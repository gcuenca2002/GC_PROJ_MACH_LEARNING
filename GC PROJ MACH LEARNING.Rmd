---
title: "GC Practical Machine Learning"
author: "Guillermo Cuenca"
date: "18 de septiembre de 2016"
output: html_document
---

###Introduction

Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement – a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. 
In this project, our goal is to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways (exercise class). We will build a model to predict the exercise class based on the data from the accelerometers.

###Project Goal

This project is to predict the manner in which the people did the exercises, which is defined in the “classe” variable in the training dataset. 
This paper describes: 
How the prediction model is built 
Cross validation
Evaluation of the expected out of sample error.
Explain the reasons of the choices made to build this model.
The prediction model is be used to predict 20 different test cases.

###Data

The training data for this project are available here:
https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv

The test data are available here:
https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv

The data for this project is provided by:
http://groupware.les.inf.puc-rio.br/har

###Libraries

load the required packages

```{r}
library(caret)
library(randomForest)
library(rpart)
library(knitr)
```

###Data Loading

Load training_data and testing_data, and then replace invalid strings as NA

```{r}
training_data <- read.csv("C:/Users/gcuenca/Documents/01 DATA SCIENCE/08 PRACTICAL MACHINE LEARNING/GC PROJ MACH LEARNING/data/pml-training.csv", na.strings = c("NA", "#DIV/0!", ""))
testing_data  <- read.csv("C:/Users/gcuenca/Documents/01 DATA SCIENCE/08 PRACTICAL MACHINE LEARNING/GC PROJ MACH LEARNING/data/pml-testing.csv",  na.strings = c("NA", "#DIV/0!", ""))

dim(training_data)

dim(testing_data)
```

###Processing Data

Delete columns with NA in testing_data

```{r}
training_data <- training_data[, colSums(is.na(testing_data)) == 0]
testing_data  <- testing_data[, colSums(is.na(testing_data)) == 0]
```

Delete some irrelevant variables: user_name, raw_timestamp_part_1, 
raw_timestamp_part_,2 cvtd_timestamp, new_window, num_window

```{r}
training_data  <- training_data[, -c(1:7)]
testing_data   <- testing_data[, -c(1:7)]

dim(training_data)

dim(testing_data)
```

###Cross Validation

In order to get out-of-sample errors,then divide training_data to sub_training_data and sub_testing_data (train, 70%) for prediction and a validation set (valid 30%) to compute the out-of-sample errors.

```{r}
part_ind <- createDataPartition(y = training_data$classe, p = 0.70, list = FALSE,)
sub_training_data  <- training_data[part_ind,]
sub_testing_data   <- training_data[-part_ind,]
```

###Create Random Forest and Decision Tree models. 
Using classification trees and random forests to predict the outcome.
Select the best.

###Decision Tree Model

```{r}
dec_tree_model  <- rpart(classe ~ ., data = sub_training_data, method = "class")
pred_dec_tree   <- predict(dec_tree_model, sub_testing_data, type = "class")
res_rand_tree   <- confusionMatrix(pred_dec_tree, sub_testing_data$classe)
```

###Random Forest Model

```{r}
rand_forest_model <- randomForest(classe ~. , data = sub_training_data, method = "class")
pred_rand_forest  <- predict(rand_forest_model, sub_testing_data, type = "class")
res_rand_forest    <- confusionMatrix(pred_rand_forest, sub_testing_data$classe)
```

###Compare models and choose with the best accuracy (random forest)

```{r}
res_comp <- data.frame(res_rand_forest$overall, res_rand_tree$overall)
res_comp
```

###Prediction on Testing Set

Using random forests to predict the outcome variable classe for the testing set.Then predict 20 different test cases. outcome levels on the testing_data using random forest model

```{r}
final_pred <- predict(rand_forest_model, testing_data, type = "class")
final_pred
```


